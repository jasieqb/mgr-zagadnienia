# Machine Learning (Uczenie Maszynowe)

## 1. Paradygmaty (rodzaje) uczenia maszynowego.


### Supervised Learning (uczenie nadzorowane)

- **Dane**: oznakowane pary (wejÅ›cie â†’ etykieta/wyjÅ›cie).
- **Typowe zadania i algorytmy**:
  - **Klasyfikacja**: Logistic Regression, SVM, Decision Tree, Random Forest, kâ€‘Nearest Neighbors, Naive Bayes, Convolutional Neural Networks (CNN).
  - **Regresja**: Linear Regression, Ridge/Lasso, Gaussian Process Regression.
- **Metody ensemble**: Bagging (Random Forest), Boosting (AdaBoost, Gradient Boosting, XGBoost, LightGBM).
- **Zastosowania**: filtrowanie spamu, wycena nieruchomoÅ›ci, wykrywanie chorÃ³b, rozpoznawanie obrazÃ³w.

---

### Unsupervised Learning (uczenie nienadzorowane)

- **Dane**: nieoznakowane.
- **Algorytmy i techniki**:
  - **Klasteryzacja**: kâ€‘means, DBSCAN, Hierarchical Clustering, Gaussian Mixture Models.
  - **Redukcja wymiarÃ³w**: PCA, tâ€‘SNE, ICA, LDA, autoenkodery.
  - **Wykrywanie anomalii**: Isolation Forest, Local Outlier Factor.
  - **Asocjacja**: Apriori, FPâ€‘growth (analiza koszykowa).
- **Zastosowania**: segmentacja klientÃ³w, wizualizacja danych, wykrywanie fraudÃ³w.

---

### Reinforcement Learning (uczenie przez wzmacnianie)

- **Mechanizm**: agent dziaÅ‚a w Å›rodowisku, otrzymuje nagrody/kary i optymalizuje strategiÄ™.
- **Algorytmy klasyczne**:
  - *Modelâ€‘free*: Qâ€‘learning, SARSA.
  - *Modelâ€‘based*: Dyna, MuZero.
- **Deep RL**: Deep Q-Network (DQN), Double DQN, Policy Gradient, Actorâ€“Critic (A2C, PPO), DDPG, SAC.
- **Zastosowania**: gry (Atari, AlphaGo), robotyka, autonomiczne pojazdy, finanse, RLHF (jak w ChatGPT).

---

### Paradygmaty hybrydowe i rozszerzenia

- **Semiâ€‘supervised**: self-training, co-training, metody grafowe.
- **Selfâ€‘supervised**: maskowanie tokenÃ³w (BERT), rotacje obrazÃ³w (SimCLR, BYOL).
- **Metaâ€‘learning**, **Online learning**, **Weak supervision**, **Genetic programming**.

---

### ğŸ“Š Tabela porÃ³wnawcza

| Paradygmat         | Dane                  | PrzykÅ‚adowe algorytmy                                               | Typowe zastosowania                     |
|--------------------|-----------------------|-----------------------------------------------------------------------|------------------------------------------|
| **Supervised**     | oznakowane            | Logistic Regression, SVM, Random Forest, CNN                         | spam, wycena, diagnostyka, klasyfikacja |
| **Unsupervised**   | nieoznakowane         | kâ€‘means, PCA, autoenkodery, Isolation Forest                        | segmentacja, wizualizacja, wykrywanie anomalii |
| **Reinforcement**  | interakcja + nagroda  | Qâ€‘learning, DQN, PPO, MuZero                                        | gry, robotyka, sterowanie, finanse      |
| **Hybrydowe**      | rÃ³Å¼ne                 | Semiâ€‘sup, selfâ€‘sup, metaâ€‘learning, weak supervision                  | NLP, medycyna, transfer learning         |

---

### âœ… Wnioski

- **Supervised**: gdy masz oznakowane dane i chcesz nauczyÄ‡ model konkretnego zadania predykcyjnego.
- **Unsupervised**: gdy dane sÄ… nieoznaczone i chcesz odkryÄ‡ strukturÄ™ bez kierowania.
- **Reinforcement**: gdy model moÅ¼e uczyÄ‡ siÄ™ poprzez interakcjÄ™ i optymalizacjÄ™ nagrÃ³d.
- **Hybrydowe**: efektywne, gdy etykiet jest maÅ‚o lub zaleÅ¼y Ci na reprezentacji.

---

## 2. PojÄ™cie parametrÃ³w i hiperparametrÃ³w modelu uczenia maszynowego â€“ modele parametryczne i nieparametryczne.


### ğŸ” Parametry w modelach parametrycznych i nieparametrycznych

#### Modele parametryczne

W modelach **parametrycznych** zakÅ‚adamy z gÃ³ry okreÅ›lonÄ… formÄ™ modelu (np. funkcja liniowa, sigmoidalna) i uczymy jedynie **skoÅ„czonÄ… liczbÄ™ parametrÃ³w**, niezaleÅ¼nie od rozmiaru danych.

- **Liczba parametrÃ³w jest staÅ‚a**
- Parametry sÄ… bezpoÅ›rednio dostrajane w procesie treningu
- Model moÅ¼e byÄ‡ **szybki w trenowaniu**, ale ograniczony w elastycznoÅ›ci (np. nie odwzoruje skomplikowanych zaleÅ¼noÅ›ci)

ğŸ”§ **PrzykÅ‚ady parametrÃ³w:**
- Regresja liniowa: wspÃ³Å‚czynniki $w_1, w_2, \ldots, w_n$, bias $b$
- Regresja logistyczna: te same co wyÅ¼ej, ale dla klasyfikacji
- Sieci neuronowe (MLP): macierze wag i biasy

#### Modele nieparametryczne

W modelach **nieparametrycznych** nie zakÅ‚adamy konkretnej formy funkcji, a liczba â€parametrÃ³wâ€ **roÅ›nie wraz z iloÅ›ciÄ… danych**. Takie modele â€zapamiÄ™tujÄ…â€ dane i opierajÄ… decyzje na ich analizie w czasie rzeczywistym.

- **Brak staÅ‚ej liczby parametrÃ³w**
- Model nie uczy siÄ™ konkretnych wag â€” decyzje opiera na strukturze danych
- Modele czÄ™sto sÄ… **bardziej elastyczne**, ale **wolniejsze przy predykcji**

ğŸ” **PrzykÅ‚ady zachowania parametrÃ³w:**
- KNN: nie ma parametrÃ³w trenowanych; do klasyfikacji wykorzystuje caÅ‚e dane treningowe
- Drzewa decyzyjne: struktura drzewa (gÅ‚Ä™bokie drzewo = duÅ¼o gaÅ‚Ä™zi) zaleÅ¼y od danych
- SVM z RBF: parametry granicy decyzyjnej zaleÅ¼Ä… od punktÃ³w wspierajÄ…cych (support vectors), ktÃ³re sÄ… wybierane z danych

---

### ğŸ”„ PorÃ³wnanie

| Cecha                    | Model parametryczny         | Model nieparametryczny        |
|--------------------------|-----------------------------|-------------------------------|
| Liczba parametrÃ³w        | StaÅ‚a                       | Zmienna (zaleÅ¼na od danych)   |
| Uczenie                  | BezpoÅ›rednia optymalizacja | "ZapamiÄ™tywanie" danych       |
| ElastycznoÅ›Ä‡             | Ograniczona                 | Wysoka                        |
| PrÄ™dkoÅ›Ä‡ predykcji       | Szybka                      | Wolniejsza                    |
| PrzykÅ‚ady                | Regresja, MLP, SVM (lin.)   | KNN, Drzewa, SVM (RBF)        |

---

### ğŸ“Œ Wnioski

- W **modelach parametrycznych** parametry sÄ… *gÅ‚Ã³wnym noÅ›nikiem wiedzy*, a ich liczba jest ustalona â€” dobÃ³r odpowiedniej architektury jest kluczowy.
- W **modelach nieparametrycznych** "parametry" sÄ… dynamiczne, a wiedza jest *rozproszona w danych* â€” modele te lepiej radzÄ… sobie z bardziej zÅ‚oÅ¼onymi rozkÅ‚adami, kosztem wydajnoÅ›ci.

---

## 3. Regresja i klasyfikacja â€“ algorytmy uczenia nadzorowanego

Uczenie nadzorowane (*supervised learning*) to podejÅ›cie w uczeniu maszynowym, w ktÃ³rym model uczy siÄ™ odwzorowywaÄ‡ relacjÄ™ pomiÄ™dzy danymi wejÅ›ciowymi a etykietami (wynikami), na podstawie zbioru treningowego zawierajÄ…cego pary (X, y). WyrÃ³Å¼niamy dwa gÅ‚Ã³wne typy problemÃ³w:

- **Regresja** â€“ gdy etykieta (y) jest zmiennÄ… ciÄ…gÅ‚Ä….
- **Klasyfikacja** â€“ gdy etykieta jest dyskretna (np. 0/1, klasa A/B/C).

---

## ğŸŸ© Regresja

**Regresja** polega na przewidywaniu wartoÅ›ci liczbowej. PrzykÅ‚ady:
- prognoza cen (np. mieszkaÅ„),
- przewidywanie temperatury, zapotrzebowania, zyskÃ³w itp.

### PrzykÅ‚adowe algorytmy regresji:
- **Regresja liniowa** â€“ dopasowuje prostÄ… liniÄ™ do danych minimalizujÄ…c bÅ‚Ä…d Å›redniokwadratowy.
- **Ridge Regression** â€“ regresja liniowa z karÄ… L2, ogranicza rozmiar wspÃ³Å‚czynnikÃ³w.
- **Lasso Regression** â€“ regresja z karÄ… L1, moÅ¼e zerowaÄ‡ nieistotne cechy.
- **Decision Tree Regressor** â€“ tworzy reguÅ‚y dzielÄ…ce dane i przypisuje wartoÅ›Ä‡ w liÅ›ciach.
- **Random Forest Regressor** â€“ agreguje wiele drzew regresyjnych dla wiÄ™kszej stabilnoÅ›ci.
- **Support Vector Regression (SVR)** â€“ dopasowuje model liniowy z tolerancjÄ… bÅ‚Ä™du (marginesem).
- **Sieci neuronowe (np. MLPRegressor)** â€“ modelujÄ… nieliniowe zaleÅ¼noÅ›ci miÄ™dzy zmiennymi.
- **XGBoost / LightGBM / CatBoost** â€“ nowoczesne, wydajne algorytmy boostingowe o wysokiej skutecznoÅ›ci.

---

## ğŸŸ¦ Klasyfikacja

**Klasyfikacja** polega na przypisaniu danych wejÅ›ciowych do jednej z klas. PrzykÅ‚ady:
- rozpoznawanie cyfr na obrazach,
- diagnoza chorÃ³b,
- wykrywanie spamu, klasyfikacja dokumentÃ³w.

### PrzykÅ‚adowe algorytmy klasyfikacji:
- **Logistic Regression** â€“ estymuje prawdopodobieÅ„stwo przynaleÅ¼noÅ›ci do klasy.
- **Decision Tree Classifier** â€“ buduje drzewo decyzji na podstawie reguÅ‚ podziaÅ‚u.
- **Random Forest Classifier** â€“ tworzy wiele drzew i gÅ‚osuje wiÄ™kszoÅ›ciÄ….
- **Support Vector Machine (SVM)** â€“ znajduje granicÄ™ maksymalizujÄ…cÄ… margines miÄ™dzy klasami.
- **K-Nearest Neighbors (KNN)** â€“ klasyfikuje na podstawie najbliÅ¼szych sÄ…siadÃ³w.
- **Naive Bayes** â€“ prosty klasyfikator probabilistyczny oparty na twierdzeniu Bayesa.
- **Sieci neuronowe (np. MLPClassifier, CNN)** â€“ uczÄ… siÄ™ nieliniowych relacji, skuteczne zwÅ‚aszcza przy duÅ¼ych i zÅ‚oÅ¼onych danych (np. obrazy, dÅºwiÄ™k).
- **XGBoost / LightGBM / CatBoost** â€“ bardzo wydajne algorytmy boostingowe, czÄ™sto osiÄ…gajÄ…ce najlepsze wyniki w zadaniach klasyfikacyjnych.

---

## ğŸ”§ Technologie i biblioteki

Do implementacji i eksperymentÃ³w najczÄ™Å›ciej wykorzystywane sÄ…:
- **Python + Scikit-learn** â€“ klasyczne algorytmy ML.
- **XGBoost / LightGBM / CatBoost** â€“ szybkie i skuteczne boostery.
- **TensorFlow / PyTorch / Keras** â€“ gÅ‚Ä™bokie sieci neuronowe.
- **H2O.ai, WEKA** â€“ narzÄ™dzia GUI lub JVM do eksploracji danych.
- **AutoML (np. AutoSklearn, H2O AutoML, Google AutoML)** â€“ automatyczny dobÃ³r modeli i hiperparametrÃ³w.


---

## 4. Algorytmy uczenia nienadzorowanego

## Algorytmy uczenia nienadzorowanego

Uczenie nienadzorowane (ang. *unsupervised learning*) to paradygmat uczenia maszynowego, w ktÃ³rym model uczy siÄ™ struktur i wzorcÃ³w z danych **bez etykiet**. Celem jest odkrycie ukrytych zaleÅ¼noÅ›ci, struktur, klastrÃ³w lub redukcja wymiarowoÅ›ci danych.

Typowe zastosowania:

- Klasteryzacja (grupowanie danych)
- Redukcja wymiarowoÅ›ci (ekstrakcja cech)
- Detekcja anomalii
- ReguÅ‚y asocjacyjne (analiza koszykowa)

---

### Kluczowe algorytmy i metody

#### ğŸ“Š Klasteryzacja

1. **K-means** â€“ dzieli dane na *k* klastrÃ³w, minimalizujÄ…c wewnÄ…trzgrupowÄ… wariancjÄ™.
2. **DBSCAN** â€“ klasteryzacja oparta na gÄ™stoÅ›ci; wykrywa klastry dowolnych ksztaÅ‚tÃ³w.
3. **Mean Shift** â€“ przesuwanie punktÃ³w do centrum gÄ™stoÅ›ci.
4. **Agglomerative Clustering** â€“ metoda hierarchiczna; Å‚Ä…czy punkty w klastry.
5. **Spectral Clustering** â€“ uÅ¼ywa wartoÅ›ci wÅ‚asnych macierzy podobieÅ„stwa.

#### ğŸ“‰ Redukcja wymiarowoÅ›ci

1. **PCA** â€“ transformacja danych do ortogonalnych komponentÃ³w.
2. **t-SNE** â€“ wizualizacja w 2D/3D, zachowujÄ…ca lokalnÄ… strukturÄ™.
3. **UMAP** â€“ szybka, nieliniowa metoda do wizualizacji i klasteryzacji.
4. **Autoenkodery** â€“ sieci neuronowe do kompresji danych.

---

### Autoenkodery (Autoencoders)

**Autoenkodery** to rodzaj sztucznych sieci neuronowych sÅ‚uÅ¼Ä…cych do **uczenia reprezentacji danych** w sposÃ³b nienadzorowany. Ich celem jest nauczenie siÄ™ zakodowanej, skompresowanej reprezentacji wejÅ›cia poprzez jego rekonstrukcjÄ™.

#### Struktura autoenkodera

Autoenkoder skÅ‚ada siÄ™ z trzech gÅ‚Ã³wnych komponentÃ³w:

1. **Encoder** â€“ przeksztaÅ‚ca dane wejÅ›ciowe w zakodowanÄ… reprezentacjÄ™ (wektor cech).
2. **Latent space (kod, wektor ukryty)** â€“ niskowymiarowa reprezentacja danych (np. 16 lub 32 wartoÅ›ci zamiast 784 pikseli).
3. **Decoder** â€“ odtwarza dane wejÅ›ciowe na podstawie zakodowanej reprezentacji.

Schemat:
WejÅ›cie â†’ Encoder â†’ Latent space â†’ Decoder â†’ WyjÅ›cie (rekonstrukcja)

---

#### Zastosowania

- **Redukcja wymiarowoÅ›ci** (alternatywa dla PCA, ale nieliniowa)
- **Denoising Autoencoders** â€“ usuwanie szumu z danych
- **Anomaly Detection** â€“ analiza odchyleÅ„ miÄ™dzy wejÅ›ciem a rekonstrukcjÄ…
- **Generowanie danych** (np. obrazy, tekst)
- **Pre-trening w uczeniu gÅ‚Ä™bokim** â€“ wstÄ™pna kompresja/ekstrakcja cech

---

#### Typy autoenkoderÃ³w

1. **Vanilla Autoencoder** â€“ najprostszy typ z gÄ™stymi warstwami (Dense).
2. **Denoising Autoencoder** â€“ uczy siÄ™ rekonstrukcji danych, ktÃ³re wczeÅ›niej celowo zaszumiono.
3. **Sparse Autoencoder** â€“ dodaje regularizacjÄ™ L1/L2, aby wymusiÄ‡ rzadkÄ… reprezentacjÄ™.
4. **Variational Autoencoder (VAE)** â€“ probabilistyczny model, koduje dane jako rozkÅ‚ady, uÅ¼ywany w generatywnych modelach (np. GANy).
5. **Convolutional Autoencoder** â€“ oparty na warstwach konwolucyjnych; lepszy dla danych obrazowych.

---

#### ğŸ§¾ ReguÅ‚y asocjacyjne (analiza koszykowa)

1. **Apriori** â€“ znajduje czÄ™ste zestawy przedmiotÃ³w i tworzy reguÅ‚y asocjacyjne.
2. **FP-Growth** â€“ efektywna alternatywa dla Apriori, dziaÅ‚a bez generowania kandydatÃ³w.
3. **Eclat** â€“ szybki algorytm oparty na przeciÄ™ciu zbiorÃ³w transakcji.

Typowe metryki:

- **Support** â€“ czÄ™stoÅ›Ä‡ wystÄ™powania zbioru.
- **Confidence** â€“ prawdopodobieÅ„stwo wystÄ…pienia B przy A.
- **Lift** â€“ siÅ‚a zaleÅ¼noÅ›ci miÄ™dzy A a B.

Zastosowania:

- E-commerce (polecanie produktÃ³w)
- Analiza zachowaÅ„ zakupowych
- Optymalizacja ukÅ‚adu sklepu

#### ğŸ” Detekcja anomalii

1. **Isolation Forest** â€“ losowe dzielenie danych w celu izolacji nietypowych punktÃ³w.
2. **One-Class SVM** â€“ model granicy dla â€normalnychâ€ obserwacji.
3. **LOF (Local Outlier Factor)** â€“ lokalna gÄ™stoÅ›Ä‡ punktÃ³w vs. sÄ…siedzi.

---

### Technologie i biblioteki

- `scikit-learn` â€“ PCA, klasteryzacja, LOF, IsolationForest
- `mlxtend` â€“ implementacja algorytmu Apriori i reguÅ‚ asocjacyjnych
- `PyCaret` â€“ szybka eksploracja modeli ML, w tym unsupervised
- `Orange3` â€“ GUI do eksploracji danych, w tym klasteryzacji i asocjacji
- `TensorFlow` / `PyTorch` â€“ autoenkodery i inne modele nienadzorowane

---

## 5. Problemy przeuczenia i niedouczenia modelu uczenia maszynowego oraz metody zapobiegania

W procesie trenowania modeli ML kluczowym wyzwaniem jest znalezienie balansu miÄ™dzy **niedouczeniem (underfitting)** a **przeuczeniem (overfitting)**. Oba te zjawiska moÅ¼na czÄ™sto zaobserwowaÄ‡ poprzez analizÄ™ wykresÃ³w bÅ‚Ä™dÃ³w: `loss` oraz `val_loss`.

---

### ğŸ” Niedouczenie (Underfitting)

Model jest **zbyt prosty**, by nauczyÄ‡ siÄ™ struktury danych.

**Objawy:**
- Wysoki `loss` i `val_loss`, oba zmniejszajÄ… siÄ™ powoli lub wcale.
- Niskie metryki (np. accuracy, F1) zarÃ³wno na danych treningowych, jak i walidacyjnych.

**Przyczyny:**
- Zbyt prosta architektura,
- Za maÅ‚o epok trenowania,
- Zbyt silna regularizacja.

**PrzykÅ‚ady algorytmÃ³w:**
- Regresja liniowa, naiwny Bayes, zbyt pÅ‚ytkie drzewa.

---

### ğŸ” Przeuczenie (Overfitting)

Model **dopasowuje siÄ™ nadmiernie** do danych treningowych, uczÄ…c siÄ™ takÅ¼e szumu.

**Objawy:**
- `loss` na zbiorze treningowym maleje, ale `val_loss` roÅ›nie po pewnym czasie.
- Model osiÄ…ga wysokie accuracy na treningu, ale niskie na walidacji.

**Typowy wykres:**

```
epoch
â”‚ val_loss
â”‚ /â€¾â€¾â€¾â€¾â€¾â€¾
â”‚ /
â”‚ /
â”‚â€¾â€¾â€¾/ loss
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**PrzykÅ‚ady algorytmÃ³w naraÅ¼onych:**
- Drzewa bez przycinania, sieci neuronowe bez `dropout`, KNN przy maÅ‚ym `k`.

---

### ğŸ› ï¸ Metody zapobiegania

| Metoda | Opis | PrzykÅ‚ad |
|--------|------|----------|
| **Early stopping** | Przerywanie trenowania, gdy `val_loss` przestaje siÄ™ poprawiaÄ‡ | `EarlyStopping(patience=5)` w Keras |
| **Regularizacja** | Ograniczenie zÅ‚oÅ¼onoÅ›ci modelu | L1/L2 (`alpha` w Ridge/Lasso), `dropout` |
| **Cross-validation** | Ocena modelu na wielu podziaÅ‚ach danych | `cross_val_score()` |
| **Data augmentation** | Rozszerzenie zbioru treningowego | Transformacje danych wejÅ›ciowych |
| **Redukcja zÅ‚oÅ¼onoÅ›ci** | Mniejsza liczba warstw, ograniczenie `max_depth` | W drzewach, sieciach |
| **Ensembles** | Agregacja prostszych modeli | Random Forest, Bagging, Boosting |

---

### ğŸ“ˆ Monitorowanie `loss`, `val_loss`, `val_accuracy`

W praktyce trenowania modeli (szczegÃ³lnie z uÅ¼yciem **Keras**, **PyTorch**) naleÅ¼y zawsze monitorowaÄ‡:
- `loss` â€“ bÅ‚Ä…d na danych treningowych,
- `val_loss` â€“ bÅ‚Ä…d na zbiorze walidacyjnym,
- `val_accuracy` lub inne metryki (np. F1, recall).

**WskazÃ³wka inÅ¼ynierska:** jeÅ›li `val_loss` zaczyna rosnÄ…Ä‡, a `loss` nadal maleje â†’ zastosuj `early stopping`, `dropout`, lub zmniejsz model.

---

### ğŸ§° Technologie i biblioteki

- `scikit-learn` â€“ klasyczne algorytmy i walidacja,
- `Keras` â€“ `EarlyStopping`, `Dropout`, `ModelCheckpoint`,
- `XGBoost`, `LightGBM` â€“ wbudowana walidacja, `early_stopping_rounds`,
- `TensorBoard` â€“ wizualizacja `loss/val_loss` i metryk.

---
